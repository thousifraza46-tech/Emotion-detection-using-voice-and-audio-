{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa22bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing core packages...\n",
      "‚úì opencv-python\n",
      "‚úì opencv-python\n",
      "‚úì SpeechRecognition\n",
      "‚úì SpeechRecognition\n",
      "‚úì transformers\n",
      "‚úì torch\n",
      "‚úì numpy\n",
      "‚úì pandas\n",
      "‚úì pillow\n",
      "‚úì gdown\n",
      "‚úì tqdm\n",
      "\n",
      "Installing TensorFlow...\n",
      "‚úó tensorflow-cpu\n",
      "\n",
      "Installing DeepFace...\n",
      "‚úó deepface\n",
      "\n",
      "Installing PyAudio...\n",
      "‚úì PyAudio\n",
      "\n",
      "‚úÖ Installation complete!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "print(\"Installing core packages...\")\n",
    "\n",
    "packages = [\n",
    "    'opencv-python',\n",
    "    'SpeechRecognition', \n",
    "    'transformers',\n",
    "    'torch',\n",
    "    'numpy',\n",
    "    'pandas',\n",
    "    'pillow',\n",
    "    'gdown',\n",
    "    'tqdm'\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])\n",
    "        print(f\"‚úì {package}\")\n",
    "    except:\n",
    "        print(f\"‚úó {package}\")\n",
    "\n",
    "print(\"\\nInstalling TensorFlow...\")\n",
    "try:\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'tensorflow-cpu'])\n",
    "    print(\"‚úì tensorflow-cpu\")\n",
    "except:\n",
    "    print(\"‚úó tensorflow-cpu\")\n",
    "\n",
    "print(\"\\nInstalling DeepFace...\")\n",
    "try:\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'deepface'])\n",
    "    print(\"‚úì deepface\")\n",
    "except:\n",
    "    print(\"‚úó deepface\")\n",
    "\n",
    "print(\"\\nInstalling PyAudio...\")\n",
    "try:\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'PyAudio'])\n",
    "    print(\"‚úì PyAudio\")\n",
    "except:\n",
    "    print(\"‚ö† PyAudio (optional - needs compiler, microphone might not work)\")\n",
    "\n",
    "print(\"\\n‚úÖ Installation complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea7a5d6-a550-413d-86cf-894a61ee45b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Multimodal Emotion Recognition Integrating Audio and Video Analysis\\env_emotion\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Initializing Multimodal Emotion Recognition System...\n",
      "============================================================\n",
      "üì¶ Loading emotion detection models...\n",
      "‚ö† FER not available. Installing...\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['d:\\\\Multimodal Emotion Recognition Integrating Audio and Video Analysis\\\\env_emotion\\\\Scripts\\\\python.exe', '-m', 'pip', 'install', '-q', 'fer']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 16\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FER\n\u001b[0;32m     17\u001b[0m     face_detector \u001b[38;5;241m=\u001b[39m FER(mtcnn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# Use faster detector\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fer'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msubprocess\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-m\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minstall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-q\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FER\n\u001b[0;32m     26\u001b[0m face_detector \u001b[38;5;241m=\u001b[39m FER(mtcnn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\subprocess.py:369\u001b[0m, in \u001b[0;36mcheck_call\u001b[1;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cmd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    368\u001b[0m         cmd \u001b[38;5;241m=\u001b[39m popenargs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 369\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, cmd)\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command '['d:\\\\Multimodal Emotion Recognition Integrating Audio and Video Analysis\\\\env_emotion\\\\Scripts\\\\python.exe', '-m', 'pip', 'install', '-q', 'fer']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import speech_recognition as sr\n",
    "from transformers import pipeline\n",
    "import threading\n",
    "import time\n",
    "import torch\n",
    "\n",
    "print(\"üöÄ Initializing Multimodal Emotion Recognition System...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"üì¶ Loading emotion detection models...\")\n",
    "\n",
    "try:\n",
    "    from fer import FER\n",
    "    face_detector = FER(mtcnn=False)\n",
    "    print(\"‚úì Video emotion detector loaded (FER)\")\n",
    "    USE_VIDEO = True\n",
    "except ImportError:\n",
    "    print(\"‚ö† FER not available. Installing...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'fer'])\n",
    "    from fer import FER\n",
    "    face_detector = FER(mtcnn=False)\n",
    "    print(\"‚úì Video emotion detector loaded (FER)\")\n",
    "    USE_VIDEO = True\n",
    "\n",
    "try:\n",
    "    emotion_classifier = pipeline(\n",
    "        \"text-classification\", \n",
    "        model=\"bhadresh-savani/distilbert-base-uncased-emotion\",\n",
    "        device=0 if torch.cuda.is_available() else -1\n",
    "    )\n",
    "    print(\"‚úì Audio emotion detector loaded (DistilBERT)\")\n",
    "    USE_AUDIO = True\n",
    "except Exception as e:\n",
    "    print(f\"‚ö† Audio emotion detector failed: {e}\")\n",
    "    USE_AUDIO = False\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "def recognize_speech():\n",
    "    if not USE_AUDIO:\n",
    "        return\n",
    "        \n",
    "    recognizer = sr.Recognizer()\n",
    "    \n",
    "    try:\n",
    "        mic = sr.Microphone()\n",
    "    except OSError as e:\n",
    "        print(f\"‚ö† Microphone not available: {e}\")\n",
    "        return\n",
    "\n",
    "    with mic as source:\n",
    "        print(\"üé§ Listening for speech...\")\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=1)\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                audio = recognizer.listen(source, timeout=5, phrase_time_limit=10)\n",
    "                print(\"üîÑ Analyzing Speech...\")\n",
    "                \n",
    "                text = recognizer.recognize_google(audio)\n",
    "                print(f\"üìù Recognized: '{text}'\")\n",
    "                \n",
    "                emotions = emotion_classifier(text)[0]\n",
    "                print(f\"üòä Speech Emotion: {emotions['label']} ({emotions['score']:.2%} confidence)\")\n",
    "                print(\"-\" * 60)\n",
    "                \n",
    "            except sr.WaitTimeoutError:\n",
    "                continue\n",
    "            except sr.RequestError as e:\n",
    "                print(f\"‚ö† Speech recognition service error: {e}\")\n",
    "                time.sleep(2)\n",
    "            except sr.UnknownValueError:\n",
    "                print(\"‚ö† Could not understand audio\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö† Error: {e}\")\n",
    "            \n",
    "            time.sleep(0.5)\n",
    "\n",
    "\n",
    "def detect_video_emotion(stop_event):\n",
    "    if not USE_VIDEO:\n",
    "        return\n",
    "        \n",
    "    print(\"üìπ Starting video emotion detection...\")\n",
    "    print(\"Press 'q' to quit video window\")\n",
    "    \n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not video_capture.isOpened():\n",
    "        print(\"‚ö† Cannot open webcam\")\n",
    "        return\n",
    "\n",
    "    frame_count = 0\n",
    "    \n",
    "    while not stop_event.is_set():\n",
    "        ret, frame = video_capture.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"‚ö† Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        \n",
    "        if frame_count % 5 == 0:\n",
    "            try:\n",
    "                emotions = face_detector.detect_emotions(frame)\n",
    "                \n",
    "                if emotions:\n",
    "                    for face in emotions:\n",
    "                        box = face[\"box\"]\n",
    "                        x, y, w, h = box\n",
    "                        \n",
    "                        emotion_scores = face[\"emotions\"]\n",
    "                        dominant_emotion = max(emotion_scores, key=emotion_scores.get)\n",
    "                        confidence = emotion_scores[dominant_emotion]\n",
    "                        \n",
    "                        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                        \n",
    "                        text = f\"{dominant_emotion}: {confidence:.2%}\"\n",
    "                        cv2.putText(frame, text, (x, y-10), \n",
    "                                  cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                        \n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "        cv2.putText(frame, \"Multimodal Emotion Recognition\", (10, 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        cv2.putText(frame, \"Press 'q' to quit\", (10, 60),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "        cv2.imshow(\"Emotion Detection - Video\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            stop_event.set()\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"üìπ Video detection stopped\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üé≠ MULTIMODAL EMOTION RECOGNITION SYSTEM\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"This system analyzes emotions from:\")\n",
    "    print(\"  üìπ Video (facial expressions)\")\n",
    "    print(\"  üé§ Audio (speech content)\")\n",
    "    print()\n",
    "    print(\"Instructions:\")\n",
    "    print(\"  - Speak naturally into your microphone\")\n",
    "    print(\"  - Look at your webcam for facial emotion detection\")\n",
    "    print(\"  - Press 'q' in video window to stop\")\n",
    "    print(\"  - Press Ctrl+C in console to force stop\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    \n",
    "    stop_event = threading.Event()\n",
    "\n",
    "    threads = []\n",
    "    \n",
    "    if USE_AUDIO:\n",
    "        speech_thread = threading.Thread(target=recognize_speech, daemon=True)\n",
    "        speech_thread.start()\n",
    "        threads.append(speech_thread)\n",
    "        print(\"‚úì Audio detection thread started\")\n",
    "    \n",
    "    if USE_VIDEO:\n",
    "        video_thread = threading.Thread(target=detect_video_emotion, args=(stop_event,))\n",
    "        video_thread.start()\n",
    "        threads.append(video_thread)\n",
    "        print(\"‚úì Video detection thread started\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "    try:\n",
    "        while not stop_event.is_set():\n",
    "            time.sleep(0.1)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n‚èπ Stopping...\")\n",
    "        stop_event.set()\n",
    "    finally:\n",
    "        stop_event.set()\n",
    "        time.sleep(1)\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"\\n‚úÖ System shutdown complete\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96539936-141b-4f36-b2c6-7c6601c7dd3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f665eef-2393-43be-853e-323d331424e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_emotion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
